"""Recording Pipeline - åéŒ²ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆ"""

from dataclasses import dataclass, field
from pathlib import Path
from typing import Callable, Optional

from loguru import logger

from ..modes.recording import Script, ScriptLine
from .avatar import (
    AvatarParts,
    AvatarRenderer,
    Expression,
    LipsyncAnalyzer,
    LipsyncConfig,
)
from .emotion import Emotion
from .subtitle import SubtitleFormat, SubtitleGenerator, SubtitleTrack
from .tts import TTSClient, TTSConfig
from .video import VideoComposer, VideoConfig, get_audio_duration_ms


@dataclass
class SubtitleConfig:
    """å­—å¹•è¨­å®š"""
    enabled: bool = True
    burn_in: bool = False  # å‹•ç”»ã«ç„¼ãè¾¼ã‚€ã‹
    formats: list[SubtitleFormat] = field(
        default_factory=lambda: [SubtitleFormat.SRT]
    )
    speaker: Optional[str] = None
    font_size: int = 48
    font_name: str = "Noto Sans CJK JP"
    margin_bottom: int = 60
    outline_width: int = 3


@dataclass
class PipelineConfig:
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³è¨­å®š"""
    tts: TTSConfig
    lipsync: LipsyncConfig
    video: VideoConfig
    avatar_parts: AvatarParts
    output_dir: Path = Path("./output")
    background_image: Optional[Path] = None
    subtitle: SubtitleConfig = field(default_factory=SubtitleConfig)

    @classmethod
    def default(cls, avatar_parts: AvatarParts) -> "PipelineConfig":
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§ç”Ÿæˆ"""
        return cls(
            tts=TTSConfig(),
            lipsync=LipsyncConfig(),
            video=VideoConfig(),
            avatar_parts=avatar_parts,
        )


@dataclass
class LineResult:
    """1è¡Œã®å‡¦ç†çµæœ"""
    line: ScriptLine
    audio_path: Path
    frames_dir: Path
    frame_count: int
    duration_ms: int


class RecordingPipeline:
    """åéŒ²ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

    å°æœ¬ â†’ TTS â†’ ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è§£æ â†’ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° â†’ å‹•ç”»å‡ºåŠ›
    """

    def __init__(self, config: PipelineConfig):
        self.config = config
        self._tts = TTSClient(config.tts)
        self._lipsync = LipsyncAnalyzer(config.lipsync)
        self._renderer = AvatarRenderer(config.avatar_parts)
        self._composer = VideoComposer(config.video)

    async def process_line(
        self,
        line: ScriptLine,
        line_index: int,
        work_dir: Path,
    ) -> LineResult:
        """1è¡Œã‚’å‡¦ç†

        Args:
            line: å°æœ¬ã®è¡Œ
            line_index: è¡Œç•ªå·ï¼ˆ0å§‹ã¾ã‚Šï¼‰
            work_dir: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

        Returns:
            LineResult
        """
        prefix = f"{line_index:04d}"
        audio_path = work_dir / "audio" / f"{prefix}.mp3"
        frames_dir = work_dir / "frames" / prefix

        # 1. TTSç”Ÿæˆ
        logger.info(f"[{line_index}] TTS: {line.text[:30]}...")
        await self._tts.synthesize(
            text=line.text,
            emotion=line.emotion.value,
            output_path=audio_path,
        )

        # 2. ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯è§£æ
        logger.info(f"[{line_index}] Lipsync analysis...")
        frames = self._lipsync.analyze_audio(audio_path)

        # æ„Ÿæƒ…ã‚’è¡¨æƒ…ã«å¤‰æ›
        expression = self._emotion_to_expression(line.emotion)
        for frame in frames:
            frame.expression = expression

        # 3. ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
        logger.info(f"[{line_index}] Rendering {len(frames)} frames...")
        self._renderer.render_animation(
            frames=frames,
            output_dir=frames_dir,
        )

        # éŸ³å£°ã®é•·ã•ã‚’å–å¾—
        duration_ms = await get_audio_duration_ms(audio_path)

        return LineResult(
            line=line,
            audio_path=audio_path,
            frames_dir=frames_dir,
            frame_count=len(frames),
            duration_ms=duration_ms,
        )

    def _emotion_to_expression(self, emotion: Emotion) -> Expression:
        """æ„Ÿæƒ…ã‚¿ã‚°ã‚’è¡¨æƒ…ã«å¤‰æ›"""
        mapping = {
            Emotion.HAPPY: Expression.HAPPY,
            Emotion.SAD: Expression.SAD,
            Emotion.EXCITED: Expression.EXCITED,
            Emotion.SURPRISED: Expression.SURPRISED,
            Emotion.ANGRY: Expression.ANGRY,
            Emotion.NEUTRAL: Expression.NEUTRAL,
        }
        return mapping.get(emotion, Expression.NEUTRAL)

    async def process_script(
        self,
        script: Script,
        progress_callback: Optional[Callable[[int, int, str], None]] = None,
    ) -> Path:
        """å°æœ¬å…¨ä½“ã‚’å‡¦ç†ã—ã¦å‹•ç”»ã‚’ç”Ÿæˆ

        Args:
            script: å°æœ¬
            progress_callback: é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ (current, total, status)

        Returns:
            å‡ºåŠ›å‹•ç”»ã®ãƒ‘ã‚¹
        """
        work_dir = self.config.output_dir / script.title.replace(" ", "_")
        work_dir.mkdir(parents=True, exist_ok=True)

        total = len(script.lines)
        results: list[LineResult] = []

        logger.info(f"Processing script: {script.title} ({total} lines)")

        # å„è¡Œã‚’å‡¦ç†
        for i, line in enumerate(script.lines):
            if progress_callback:
                progress_callback(i + 1, total, f"Processing line {i + 1}...")

            result = await self.process_line(line, i, work_dir)
            results.append(result)

        # å­—å¹•ã‚’ç”Ÿæˆ
        subtitle_paths: dict[SubtitleFormat, Path] = {}
        if self.config.subtitle.enabled:
            if progress_callback:
                progress_callback(total, total, "Generating subtitles...")

            subtitle_paths = self._generate_subtitles(results, work_dir, script.title)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å‹•ç”»ã«çµåˆ
        if progress_callback:
            progress_callback(total, total, "Composing video...")

        output_path = work_dir / f"{script.title.replace(' ', '_')}.mp4"

        segments = [
            {"audio": r.audio_path, "frames_dir": r.frames_dir}
            for r in results
        ]

        success = await self._composer.compose_from_segments(
            segments=segments,
            output_path=output_path,
            background_image=self.config.background_image,
        )

        if not success:
            raise RuntimeError("Failed to compose video")

        # å­—å¹•ç„¼ãè¾¼ã¿
        if self.config.subtitle.burn_in and SubtitleFormat.SRT in subtitle_paths:
            if progress_callback:
                progress_callback(total, total, "Burning in subtitles...")

            burned_path = output_path.with_stem(output_path.stem + "_subtitled")
            burn_success = await self._composer.burn_subtitles(
                video_path=output_path,
                subtitle_path=subtitle_paths[SubtitleFormat.SRT],
                output_path=burned_path,
                font_size=self.config.subtitle.font_size,
                font_name=self.config.subtitle.font_name,
                margin_bottom=self.config.subtitle.margin_bottom,
                outline_width=self.config.subtitle.outline_width,
            )
            if burn_success:
                # ç„¼ãè¾¼ã¿ç‰ˆã‚’æœ¬ä½“ã«ãƒªãƒãƒ¼ãƒ 
                output_path.unlink()
                burned_path.rename(output_path)
                logger.info("Subtitles burned into video")

        logger.info(f"âœ… Video created: {output_path}")
        if subtitle_paths:
            logger.info(f"ğŸ“ Subtitles: {list(subtitle_paths.values())}")
        return output_path

    def _generate_subtitles(
        self,
        results: list[LineResult],
        work_dir: Path,
        title: str,
    ) -> dict[SubtitleFormat, Path]:
        """åéŒ²çµæœã‹ã‚‰å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
        sub_config = self.config.subtitle
        generator = SubtitleGenerator(speaker=sub_config.speaker)
        track = generator.create_track(title)

        current_time_ms = 0
        gap_ms = 200  # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé–“ã®ã‚®ãƒ£ãƒƒãƒ—

        for result in results:
            text = result.line.text.strip()
            duration_ms = result.duration_ms if result.duration_ms > 0 else 2000

            if text:
                track.add_entry(
                    text=text,
                    start_ms=current_time_ms,
                    end_ms=current_time_ms + duration_ms,
                    speaker=sub_config.speaker,
                )

            current_time_ms += duration_ms
            current_time_ms += int(result.line.wait_after * 1000)
            current_time_ms += gap_ms

        # ä¿å­˜
        output_paths: dict[SubtitleFormat, Path] = {}
        base_name = title.replace(" ", "_")

        for fmt in sub_config.formats:
            out_path = work_dir / f"{base_name}.{fmt.value}"
            track.save(out_path, fmt)
            output_paths[fmt] = out_path

        logger.info(f"Generated subtitles: {list(output_paths.values())}")
        return output_paths

    async def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾"""
        await self._tts.close()

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()


async def quick_record(
    script_path: Path,
    avatar_parts: AvatarParts,
    output_dir: Optional[Path] = None,
    tts_config: Optional[TTSConfig] = None,
) -> Path:
    """ç°¡æ˜“åéŒ²é–¢æ•°

    Args:
        script_path: å°æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        avatar_parts: ã‚¢ãƒã‚¿ãƒ¼ãƒ‘ãƒ¼ãƒ„
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆçœç•¥æ™‚ã¯./outputï¼‰
        tts_config: TTSè¨­å®šï¼ˆçœç•¥æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

    Returns:
        å‡ºåŠ›å‹•ç”»ã®ãƒ‘ã‚¹
    """
    script = Script.from_file(script_path)

    config = PipelineConfig(
        tts=tts_config or TTSConfig(),
        lipsync=LipsyncConfig(),
        video=VideoConfig(),
        avatar_parts=avatar_parts,
        output_dir=output_dir or Path("./output"),
    )

    async with RecordingPipeline(config) as pipeline:
        return await pipeline.process_script(script)
